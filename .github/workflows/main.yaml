name: workflow

on:
  push:
    branches:
      - main
    paths-ignore:
      - 'README.md'

permissions:
  id-token: write
  contents: read

jobs:
  integration:
    name: Continuous Integration
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Lint code
        run: echo "Linting repository"

      - name: Run unit tests
        run: echo "Running unit tests"

  build-and-push-ecr-image:
    name: Continuous Delivery
    needs: integration
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Install Utilities
        run: |
          sudo apt-get update
          sudo apt-get install -y jq unzip
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build, tag, and push image to Amazon ECR
        id: build-image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY_NAME }}
          IMAGE_TAG: latest
        run: |
          # Build a docker container and
          # push it to ECR so that it can
          # be deployed to ECS.
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          echo "::set-output name=image::$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"
          
          
  Continuous-Deployment:
    needs: build-and-push-ecr-image
    runs-on: self-hosted
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Free up disk space immediately
        run: |
          echo "=== EMERGENCY DISK CLEANUP ==="
          # Check current space
          AVAILABLE_KB=$(df / | awk 'NR==2 {print $4}')
          AVAILABLE_GB=$((AVAILABLE_KB / 1024 / 1024))
          echo "Current available space: ${AVAILABLE_GB}GB"
          
          echo "=== Analyzing disk usage ==="
          echo "Top 10 largest directories:"
          du -h --max-depth=2 / 2>/dev/null | sort -hr | head -10 || true
          
          # Stop Docker daemon first for complete cleanup
          echo "Stopping Docker daemon..."
          sudo systemctl daemon-reload
          sudo systemctl stop docker.socket docker.service || true
          
          # Remove all Docker data completely
          echo "Removing all Docker data..."
          sudo rm -rf /var/lib/docker/* 2>/dev/null || true
          sudo rm -rf /var/lib/containerd/* 2>/dev/null || true
          
          # Clean system directories aggressively
          echo "Cleaning system directories..."
          sudo rm -rf /opt/hostedtoolcache/* 2>/dev/null || true
          sudo rm -rf /usr/share/dotnet 2>/dev/null || true
          sudo rm -rf /usr/local/lib/android 2>/dev/null || true
          sudo rm -rf /usr/local/share/boost 2>/dev/null || true
          sudo rm -rf /usr/local/lib/node_modules 2>/dev/null || true
          sudo rm -rf /usr/local/go 2>/dev/null || true
          sudo rm -rf /usr/local/julia* 2>/dev/null || true
          sudo rm -rf /home/runner/.cache/* 2>/dev/null || true
          sudo rm -rf /root/.cache/* 2>/dev/null || true
          sudo rm -rf /tmp/* 2>/dev/null || true
          sudo rm -rf /var/tmp/* 2>/dev/null || true
          sudo rm -rf ~/.cache/* 2>/dev/null || true
          
          # Clean more aggressive system files
          echo "Additional system cleanup..."
          sudo rm -rf /var/lib/apt/lists/* 2>/dev/null || true
          sudo rm -rf /usr/share/doc/* 2>/dev/null || true
          sudo rm -rf /usr/share/man/* 2>/dev/null || true
          sudo rm -rf /usr/share/locale/* 2>/dev/null || true
          sudo rm -rf /var/cache/* 2>/dev/null || true
          sudo rm -rf /home/runner/.npm/* 2>/dev/null || true
          sudo rm -rf /home/runner/.cargo/* 2>/dev/null || true
          sudo rm -rf /home/runner/.rustup/* 2>/dev/null || true
          
          # Clean package manager caches
          echo "Cleaning package caches..."
          sudo apt-get clean 2>/dev/null || true
          sudo apt-get autoremove --purge -y 2>/dev/null || true
          sudo apt-get autoclean -y 2>/dev/null || true
          
          # Clean logs aggressively
          sudo journalctl --vacuum-size=1M 2>/dev/null || true
          sudo rm -rf /var/log/* 2>/dev/null || true
          sudo find /var/log -type f -delete 2>/dev/null || true
          
          # Clear Python caches
          find /usr -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
          find /usr -name "*.pyc" -delete 2>/dev/null || true
          
          # Restart Docker
          echo "Restarting Docker daemon..."
          sudo systemctl daemon-reload
          sudo systemctl start docker.service
          sleep 20
          
          # Show final space
          echo "=== SPACE AFTER CLEANUP ==="
          df -h /
          
          # Verify we have enough space
          FINAL_KB=$(df / | awk 'NR==2 {print $4}')
          FINAL_GB=$((FINAL_KB / 1024 / 1024))
          echo "Final available space: ${FINAL_GB}GB"
          
          if [ $FINAL_GB -lt 3 ]; then
            echo "❌ ERROR: Still only ${FINAL_GB}GB available after cleanup."
            echo "=== DISK USAGE ANALYSIS ==="
            echo "Remaining large directories:"
            du -h --max-depth=2 / 2>/dev/null | sort -hr | head -15 || true
            echo ""
            echo "Your 6.8GB runner is too small for Docker operations. You need:"
            echo "1. At least 15GB disk space for reliable Docker operations"
            echo "2. Consider using a larger EC2 instance"
            echo "3. Or use GitHub-hosted runners instead of self-hosted"
            exit 1
          fi

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1
      
      - name: Stop and remove existing mltest container
        run: |
          if docker ps -q --filter "name=mltest" | grep -q .; then
            echo "Stopping existing mltest container..."
            docker stop mltest
            docker rm -f mltest
          else
            echo "No existing mltest container found"
          fi
      
      - name: Pre-pull disk space check
        run: |
          echo "=== Checking available space before pulling image ==="
          AVAILABLE_KB=$(df / | awk 'NR==2 {print $4}')
          AVAILABLE_GB=$((AVAILABLE_KB / 1024 / 1024))
          echo "Available space: ${AVAILABLE_GB}GB"
          
          if [ $AVAILABLE_GB -lt 5 ]; then
            echo "⚠️  WARNING: Less than 5GB available for image pull!"
            echo "Performing additional aggressive cleanup..."
            
            # Stop Docker daemon temporarily and clean everything
            sudo systemctl stop docker
            
            # Clean Docker root directory more aggressively
            sudo rm -rf /var/lib/docker/tmp/* 2>/dev/null || true
            sudo rm -rf /var/lib/docker/overlay2/* 2>/dev/null || true
            sudo rm -rf /var/lib/docker/image/* 2>/dev/null || true
            sudo rm -rf /var/lib/docker/containers/* 2>/dev/null || true
            
            # Clean more system directories
            sudo rm -rf /opt/hostedtoolcache/* 2>/dev/null || true
            sudo rm -rf /usr/share/dotnet 2>/dev/null || true
            sudo rm -rf /usr/local/lib/android 2>/dev/null || true
            sudo rm -rf /usr/local/share/boost 2>/dev/null || true
            sudo rm -rf /usr/local/lib/node_modules 2>/dev/null || true
            sudo rm -rf /home/runner/.cache/* 2>/dev/null || true
            sudo rm -rf /root/.cache/* 2>/dev/null || true
            
            # Clean package manager caches
            sudo apt-get autoremove -y 2>/dev/null || true
            sudo apt-get autoclean -y 2>/dev/null || true
            sudo journalctl --vacuum-time=1d 2>/dev/null || true
            
            # Restart Docker
            sudo systemctl start docker
            sleep 10
            
            echo "=== Space after aggressive cleanup ==="
            df -h /
          fi
      
      - name: Pull latest images with chunked strategy
        run: |
          echo "=== Final pre-pull space check ==="
          df -h /
          
          # Check if we have enough space (at least 2.5GB)
          AVAILABLE_KB=$(df / | awk 'NR==2 {print $4}')
          AVAILABLE_GB=$((AVAILABLE_KB / 1024 / 1024))
          
          if [ $AVAILABLE_GB -lt 3 ]; then
            echo "⚠️  WARNING: Only ${AVAILABLE_GB}GB available. This is risky but proceeding..."
            echo "Performing final cleanup before pull..."
            docker system prune -af --volumes 2>/dev/null || true
            sudo rm -rf /tmp/* /var/tmp/* 2>/dev/null || true
          fi
          
          echo "✅ Space available: ${AVAILABLE_GB}GB"
          echo "Pulling latest image with streaming to minimize disk usage..."
          
          # Pull with retry mechanism and better error handling
          IMAGE_URI="${{secrets.AWS_ECR_LOGIN_URI}}/${{ secrets.ECR_REPOSITORY_NAME }}:latest"
          
          for i in {1..3}; do
            echo "Pull attempt $i/3..."
            # Use docker pull without --quiet to see progress and detect issues early
            if timeout 300 docker pull "$IMAGE_URI"; then
              echo "✅ Image pulled successfully"
              break
            else
              echo "❌ Pull attempt $i failed"
              if [ $i -eq 3 ]; then
                echo "All pull attempts failed. Final space check..."
                df -h /
                echo "Remaining space analysis:"
                du -h --max-depth=1 /var/lib/docker 2>/dev/null | sort -hr || true
                exit 1
              fi
              
              echo "Cleaning up before retry..."
              docker system prune -af
              sudo rm -rf /tmp/* /var/tmp/* 2>/dev/null || true
              sleep 5
            fi
          done
          
          echo "=== Post-pull space check ==="
          df -h /
         
      - name: Clean up old images after pull
        run: |
          echo "Removing old versions of the same image..."
          # Keep only the latest tag and remove other versions
          IMAGE_REPO="${{secrets.AWS_ECR_LOGIN_URI}}/${{ secrets.ECR_REPOSITORY_NAME }}"
          docker images --format "{{.Repository}}:{{.Tag}} {{.ID}}" | grep "$IMAGE_REPO" | grep -v ":latest" | awk '{print $2}' | xargs -r docker rmi 2>/dev/null || true
         
      - name: Run Docker Image to serve users
        run: |
          echo "Starting new mltest container..."
          docker run -d -p 8080:8080 --ipc="host" --name=mltest \
            -e 'AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}' \
            -e 'AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}' \
            -e 'AWS_REGION=${{ secrets.AWS_REGION }}' \
            ${{secrets.AWS_ECR_LOGIN_URI}}/${{ secrets.ECR_REPOSITORY_NAME }}:latest

      - name: Verify container is running
        run: |
          echo "Checking container status..."
          docker ps --filter "name=mltest"
          
      - name: Final cleanup of unused resources
        run: |
          echo "Final cleanup of unused images and containers..."
          docker system prune -f
